{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"About Facets.cloud Facets.cloud is a cloud automation platform for Developers and DevSecOps. Facets.cloud simplifies provisioning and change management of applications, infrastructure components and databases on multiple cloud platforms. Features Any deployment provisioned through Facets.cloud automatically gets continuous deployments, observability, Security practices and disaster recovery features. 1. Declarative Provisioning Define your complete product stack (blueprint) in an easy to write Facets.cloud Stack Definition Language (JSON). The blueprint contains application definitions, cloud resources, database specifications and the dependencies between them. The blueprint is version/access controlled and any number of deployments can be manifested out of it. These deployments can be QA, Staging, Load Test or multiple production environments on different cloud providers. 2. Continuous Mutations Once deployed through Facets.cloud, the entire deployment can receive continuous mutations. These mutations can be regular application releases integrated with the CI systems or can be changes to resources like Databases, queues and their properties. Facets.cloud ensures that all changes are consistently deployed across all deployments of the stack. 3. Optimized cloud cost Any deployment provisioned through Facets.cloud gets the best practice implementation for auto-scaling, spot utilization for optimal cloud spend. Additionally, since all resources and their dependencies are accounted for in the blueprint, the cost leakage is minimized. 4. Observability First Facets.cloud components are developed with observability first approach. Infrastructure, application and cloud resource metrics get aggregated and pre-built dashboards and well-researched alerts are auto-configured. The alerts are pushed to chat-ops tools and custom notification channels. 5. Built-in Security and compliance Deployments receive best practice point-to-site connectivity for developers and devops with role based access control. Networks, Security, SSL certificates are auto provisioned and managed by Facets. Antivirus, OSSEC tools come built-in with pre-built dashboards for monitoring and compliance. Facets.cloud ensures all critical components like Databases are backed by a disaster recovery solution. Presentation How is Facets.cloud built? Facets.cloud is built on open standards like Kubernetes, Open Telemetry. It leverages the best of the offerings of the cloud providers by being cloud native and at the same time supports multiple cloud platforms and local development environments. About the Company Facets.cloud is an independent entity that is incubated under Capillary Technologies , a leading SaaS product in the customer engagement sector. Currently, it manages applications hosted on several thousands of nodes provisioned on AWS public cloud. Facets.cloud has helped in reducing 15% of production issues emerging from automation gaps.","title":"Introduction"},{"location":"#about-facetscloud","text":"Facets.cloud is a cloud automation platform for Developers and DevSecOps. Facets.cloud simplifies provisioning and change management of applications, infrastructure components and databases on multiple cloud platforms.","title":"About Facets.cloud"},{"location":"#features","text":"Any deployment provisioned through Facets.cloud automatically gets continuous deployments, observability, Security practices and disaster recovery features. 1. Declarative Provisioning Define your complete product stack (blueprint) in an easy to write Facets.cloud Stack Definition Language (JSON). The blueprint contains application definitions, cloud resources, database specifications and the dependencies between them. The blueprint is version/access controlled and any number of deployments can be manifested out of it. These deployments can be QA, Staging, Load Test or multiple production environments on different cloud providers. 2. Continuous Mutations Once deployed through Facets.cloud, the entire deployment can receive continuous mutations. These mutations can be regular application releases integrated with the CI systems or can be changes to resources like Databases, queues and their properties. Facets.cloud ensures that all changes are consistently deployed across all deployments of the stack. 3. Optimized cloud cost Any deployment provisioned through Facets.cloud gets the best practice implementation for auto-scaling, spot utilization for optimal cloud spend. Additionally, since all resources and their dependencies are accounted for in the blueprint, the cost leakage is minimized. 4. Observability First Facets.cloud components are developed with observability first approach. Infrastructure, application and cloud resource metrics get aggregated and pre-built dashboards and well-researched alerts are auto-configured. The alerts are pushed to chat-ops tools and custom notification channels. 5. Built-in Security and compliance Deployments receive best practice point-to-site connectivity for developers and devops with role based access control. Networks, Security, SSL certificates are auto provisioned and managed by Facets. Antivirus, OSSEC tools come built-in with pre-built dashboards for monitoring and compliance. Facets.cloud ensures all critical components like Databases are backed by a disaster recovery solution.","title":"Features"},{"location":"#presentation","text":"","title":"Presentation"},{"location":"#how-is-facetscloud-built","text":"Facets.cloud is built on open standards like Kubernetes, Open Telemetry. It leverages the best of the offerings of the cloud providers by being cloud native and at the same time supports multiple cloud platforms and local development environments.","title":"How is Facets.cloud built?"},{"location":"#about-the-company","text":"Facets.cloud is an independent entity that is incubated under Capillary Technologies , a leading SaaS product in the customer engagement sector. Currently, it manages applications hosted on several thousands of nodes provisioned on AWS public cloud. Facets.cloud has helped in reducing 15% of production issues emerging from automation gaps.","title":"About the Company"},{"location":"getting_started/demo/","text":"Demo Following demo showcases certain basic features and principles of Facets.cloud product Scenario Awesomeness Inc. is a company having two product suites \u201cS3 file uploader\u201d and \u201cTodo App\u201d. S3 uploader application needs to be deployed in a VPC and has various components to it. Todo app too needs a separate VPC and has couple of microservices and database in it. Awesomeness Inc. is a Facets customer and has its own control plane. We will sit through the company's journey of creation of these stacks in Facets product. Video","title":"Video Tutorial"},{"location":"getting_started/demo/#demo","text":"Following demo showcases certain basic features and principles of Facets.cloud product","title":"Demo"},{"location":"getting_started/demo/#scenario","text":"Awesomeness Inc. is a company having two product suites \u201cS3 file uploader\u201d and \u201cTodo App\u201d. S3 uploader application needs to be deployed in a VPC and has various components to it. Todo app too needs a separate VPC and has couple of microservices and database in it. Awesomeness Inc. is a Facets customer and has its own control plane. We will sit through the company's journey of creation of these stacks in Facets product.","title":"Scenario"},{"location":"getting_started/demo/#video","text":"","title":"Video"},{"location":"getting_started/prerequisites/","text":"Onboarding Applications to facets. In order to migrate your applications to Facets we would need them to be dockerized and ready for kubernetes deployments. Following are few guidelines to follow while containerising your applications or readying your existing containers. Checkout the best practices for creating a docker image here and here Logging: Applications must log into stdout/stderr and not files. Read here for java application Environment Variables: Use environment variables for reading all database usernames and passwords in your applications. This will later help us auto-wire these details and manage credential management for you once you are on Facets. Use environment variables to refer to any cloud resource like S3, SQS or SNS. Facets can then dynamically fulfil these variables. AWS SDK (If Used): Use AWS keys and secrets in your applications via environment variables, rather use the default credential provider. This will enable auto provision the IAM for your application and have seamless access to resources it has requested Details here . Image Registry: Use either dockerhub private registry or Amazon Elastic Container Registry (Amazon ECR) for storing your docker images. Facets has support for onboarding these registries and can pull images from here. Service Discovery: Use either DNS or IP based service discovery via environment variables for communication between services and/ or databases easier. This will enable easy porting into kubernetes on Facets. Readiness and Liveliness checks: Readiness and Liveliness checks are important and should be configured appropriately to keep your application well managed. Read here for more details","title":"Prerequisites"},{"location":"getting_started/prerequisites/#onboarding-applications-to-facets","text":"In order to migrate your applications to Facets we would need them to be dockerized and ready for kubernetes deployments. Following are few guidelines to follow while containerising your applications or readying your existing containers. Checkout the best practices for creating a docker image here and here","title":"Onboarding Applications to facets."},{"location":"getting_started/prerequisites/#logging","text":"Applications must log into stdout/stderr and not files. Read here for java application","title":"Logging:"},{"location":"getting_started/prerequisites/#environment-variables","text":"Use environment variables for reading all database usernames and passwords in your applications. This will later help us auto-wire these details and manage credential management for you once you are on Facets. Use environment variables to refer to any cloud resource like S3, SQS or SNS. Facets can then dynamically fulfil these variables.","title":"Environment Variables:"},{"location":"getting_started/prerequisites/#aws-sdk-if-used","text":"Use AWS keys and secrets in your applications via environment variables, rather use the default credential provider. This will enable auto provision the IAM for your application and have seamless access to resources it has requested Details here .","title":"AWS SDK (If Used):"},{"location":"getting_started/prerequisites/#image-registry","text":"Use either dockerhub private registry or Amazon Elastic Container Registry (Amazon ECR) for storing your docker images. Facets has support for onboarding these registries and can pull images from here.","title":"Image Registry:"},{"location":"getting_started/prerequisites/#service-discovery","text":"Use either DNS or IP based service discovery via environment variables for communication between services and/ or databases easier. This will enable easy porting into kubernetes on Facets.","title":"Service Discovery:"},{"location":"getting_started/prerequisites/#readiness-and-liveliness-checks","text":"Readiness and Liveliness checks are important and should be configured appropriately to keep your application well managed. Read here for more details","title":"Readiness and Liveliness checks:"},{"location":"on_boarding/concepts/","text":"Concepts Stack A stack is a technical blue print of your software product. It defines the resources (viz. databases, applications, cloud resources) and the relationships between them. The definitions reside in a git repository, as version controlling the stack is critical for rollbacks, tracking and attribution. Each resource type has a directory named after it. Each resource is defined by a JSON file, usually placed in the instances directory of a resource type. The above example defines 4 applications (backend, frontend, rockmongo and s3demo), 1 ingress (demoingress), 1 mongodb ( demomongo) and 1 s3 bucket (s3demo) A stack defines a few other metadata like common environment variables, extensions used, disaster recovery policy and allowed sizings etc Cluster A stack can be used to create clusters in a cloud provider of choice. A cluster is essentially a Kubernetes cluster that houses the defined Kubernetes resources and dedicated cloud resource instances defined in the stack. Control Plane Control plane is the web UI to create, manage and operate stacks and clusters.","title":"Concepts"},{"location":"on_boarding/concepts/#concepts","text":"","title":"Concepts"},{"location":"on_boarding/concepts/#stack","text":"A stack is a technical blue print of your software product. It defines the resources (viz. databases, applications, cloud resources) and the relationships between them. The definitions reside in a git repository, as version controlling the stack is critical for rollbacks, tracking and attribution. Each resource type has a directory named after it. Each resource is defined by a JSON file, usually placed in the instances directory of a resource type. The above example defines 4 applications (backend, frontend, rockmongo and s3demo), 1 ingress (demoingress), 1 mongodb ( demomongo) and 1 s3 bucket (s3demo) A stack defines a few other metadata like common environment variables, extensions used, disaster recovery policy and allowed sizings etc","title":"Stack"},{"location":"on_boarding/concepts/#cluster","text":"A stack can be used to create clusters in a cloud provider of choice. A cluster is essentially a Kubernetes cluster that houses the defined Kubernetes resources and dedicated cloud resource instances defined in the stack.","title":"Cluster"},{"location":"on_boarding/concepts/#control-plane","text":"Control plane is the web UI to create, manage and operate stacks and clusters.","title":"Control Plane"},{"location":"on_boarding/control_plane/","text":"Getting Facets Control plane You will need the Facets control plane to start spawning clusters in cloud of your choice. There are two types of control planes which can be deployed by Facets. Private Facets.cloud would deploy a private control plane in a AWS Account owned by you and you can create and manage stacks and clusters using the same. This would deploy a bare minimum K8s cluster to host the control plane stack for you. Interesting Fact: Even the control plane is a Facets stack. Shared Facets.cloud will host a control plane in its own cloud and will pass on the credentials to you to manage the stacks and clusters. Getting access Right now the access to control plane is on invite basis only and you can contact us to get a trial account with us.","title":"Get your Control Plane"},{"location":"on_boarding/control_plane/#getting-facets-control-plane","text":"You will need the Facets control plane to start spawning clusters in cloud of your choice. There are two types of control planes which can be deployed by Facets.","title":"Getting Facets Control plane"},{"location":"on_boarding/control_plane/#private","text":"Facets.cloud would deploy a private control plane in a AWS Account owned by you and you can create and manage stacks and clusters using the same. This would deploy a bare minimum K8s cluster to host the control plane stack for you. Interesting Fact: Even the control plane is a Facets stack.","title":"Private"},{"location":"on_boarding/control_plane/#shared","text":"Facets.cloud will host a control plane in its own cloud and will pass on the credentials to you to manage the stacks and clusters.","title":"Shared"},{"location":"on_boarding/control_plane/#getting-access","text":"Right now the access to control plane is on invite basis only and you can contact us to get a trial account with us.","title":"Getting access"},{"location":"on_boarding/create_cluster/","text":"Creating a Cluster To create a cluster, select the stack on Control Plane and click \u201cCreate Cluster\u201c. Choose the Cloud Provided and fill in the details. If the stack has cluster level variables/secrets defined values for those need to be provided at creation time.","title":"Create a Cluster"},{"location":"on_boarding/create_cluster/#creating-a-cluster","text":"To create a cluster, select the stack on Control Plane and click \u201cCreate Cluster\u201c. Choose the Cloud Provided and fill in the details. If the stack has cluster level variables/secrets defined values for those need to be provided at creation time.","title":"Creating a Cluster"},{"location":"on_boarding/create_stack/","text":"Create a stack By now you must be familiar with the concept of a stack. Git Repository Create a Github/Bitbucket git repository. To get started, a stack.json file would qualify the repository as a valid stack. { \"clusterVariablesMeta\" : { }, \"stackVariables\" : { } } Register Stack on Control Plane Navigate to Create Stack button on the Control Plane and fill in the details. Creating an Application Definition An application may be defined by placing a json file in application/instances directory in stack. { \"size\" : \"SMALL\" , \"deploymentStrategy\" : \"RollingUpdate\" , \"elbIdleTimeoutSeconds\" : 300 , \"protocolGroup\" : \"tcp\" , \"scaling\" : { \"hpaEnabled\" : true , \"hpaMinReplicas\" : 1 , \"hpaMaxReplicas\" : 1 , \"hpaMetricThreshold\" : 60 }, \"liveness\" : { \"enableLivenessTCP\" : true , \"livenessPort\" : 8080 , \"livenessInitialDelay\" : 60 , \"livenessTimeout\" : 10 , \"livenessFailureThreshold\" : 20 , \"livenessPeriod\" : 60 , \"livenessSuccessThreshold\" : 1 }, \"readiness\" : { \"enableReadinessTCP\" : true , \"readinessInitialDelay\" : 30 , \"readinessFailureThreshold\" : 8 , \"readinessSuccessThreshold\" : 1 , \"readinessPort\" : 8080 , \"readinessTimeout\" : 10 , \"readinessPeriod\" : 60 }, \"ports\" : [ { \"name\" : \"http\" , \"containerPort\" : 8080 , \"lbPort\" : 80 } ], \"build\" : { \"ci\" : \"deployer\" , \"id\" : \"5e301d0aa4a81300073aba10\" }, \"credentialRequests\" : { \"dbs\" : { \"mysql\" : [ { \"resourceType\" : \"mysql\" , \"resourceName\" : \"billdump\" , \"permission\" : \"READ_WRITE\" , \"environmentVariables\" : [ { \"userName\" : \"INTOUCH_DB_MYSQL_FILESERVICE_USERNAME\" , \"password\" : \"INTOUCH_DB_MYSQL_FILESERVICE_PASSWORD\" } ] } ], \"mongo\" : [] }, \"queues\" : { \"rabbitmq\" : [] }, \"cloud\" : [ { \"resourceType\" : \"s3\" , \"resourceName\" : \"fileservice\" , \"permission\" : \"READ_WRITE\" }, { \"resourceType\" : \"s3\" , \"resourceName\" : \"reon-etl-data\" , \"permission\" : \"READ_WRITE\" }, { \"resourceType\" : \"s3\" , \"resourceName\" : \"campaigns\" , \"permission\" : \"READ_WRITE\" }, { \"resourceType\" : \"s3\" , \"resourceName\" : \"sharingan\" , \"permission\" : \"READ_WRITE\" }, { \"resourceType\" : \"s3\" , \"resourceName\" : \"nsadmindata\" , \"permission\" : \"READ_WRITE\" } ] }, \"environmentVariables\" : { \"static\" : { \"XMX_VALUE\" : \"1573m\" , \"XMS_VALUE\" : \"1573m\" }, \"dynamic\" : { \"FILESERVICE_BUCKET\" : { \"resourceType\" : \"s3\" , \"resourceName\" : \"fileservice\" , \"attribute\" : \"bucket_name\" }, \"CAMPAIGNS_FILESERVICE_BUCKET_NAME\" : { \"resourceType\" : \"s3\" , \"resourceName\" : \"campaigns\" , \"attribute\" : \"bucket_name\" }, \"NSADMINDATA_FILESERVICE_BUCKET_NAME\" : { \"resourceType\" : \"s3\" , \"resourceName\" : \"nsadmindata\" , \"attribute\" : \"bucket_name\" } } }, \"k8s_service_names\" : [ \"fileservice\" ], \"ingress_rules\" : [ { \"ingress\" : \"demoingress\" , \"path\" : \"/\" , \"targetPort\" : 3000 , \"domainPrefix\" : \"fileservice.\" } ], \"resourceAllocationStrategy\" : \"GENERAL_PURPOSE\" } Size Pod sizing to use as define in sizing json. ResourceAllocationStrategy drives which sizing family to use. Deployment Strategy Supported deployment strategies are RollingUpdate and Replace Protocol Group Protocol groups maybe TCP or UDP Scaling Configurations HPA configurations Liveliness/Readiness Probes Liveliness or readiness probes maybe a Port Check, HTTP Probe or a Script probe. The three modes maybe switched by setting the boolean flags enableLivenessTCP, enableLivenessHTTP or enableLivenessEXEC. For Script probe, readinessCommand or livenessCommand arrays define the command to run. Ports Declare the ports Build Selection Images are selected based on the ci system (deployer), id of the build job (deployer id), and the release stream selected for the cluster. Credential Management Credential requests can inject usernames and passwords for databases/queues into environment variables. These users are created dynamically. Cloud credential requests are fulfilled using cloud specific mechanisms (Eg. kube2iam for aws) Static Environment Variables Static environment variables are tuning parameters like Xmx or threadPool counts. These may be readjusted at a cluster level using overrides from the control plane. Dynamic Environment Variables Dynamic environment variables may be used to inject attributes of other resources for eg. S3 bucket name, SQS queue name etc into application environment variables. Service Discovery A Kubernetes service with the same name as the json file name in the default namespace is created. If any specific service name is desired that maybe specified using k8s_service_names Ingress An application may be exposed outside the Kubernetes cluster using an ingress. An ingress resource needs to be defined which may be internal (accessible within VPC) or external (accessible via internet). Applications can add rules to direct traffic at them using ingress_rules field in application definition. Rules may be path based or subdomain based. Empty subdomain implies the cluster base domain as defined in the ingress resource is used. Application Sizing The pod sizings to be used can be predefined in a stack. The convention is to have different sizing families viz. CPU_INTENSIVE, GENERAL_PURPOSE etc. The files have to be named: application/sizing.{SIZING_FAMILY}.json Example: application/sizing.CPU_INTENSIVE.json { \"SMALL\" : { \"podCPULimit\" : 1 , \"podMemoryLimit\" : 2 }, \"LARGE\" : { \"podCPULimit\" : 2 , \"podMemoryLimit\" : 4 }, \"XLARGE\" : { \"podCPULimit\" : 3 , \"podMemoryLimit\" : 6 }, \"XXLARGE\" : { \"podCPULimit\" : 6 , \"podMemoryLimit\" : 10 }, \"TINY\" : { \"podCPULimit\" : 0.5 , \"podMemoryLimit\" : 1 }, \"MICRO\" : { \"podCPULimit\" : 0.25 , \"podMemoryLimit\" : 0.5 } } Common Environment Variables Stack Variables Any fixed environment variables that need to be injected into all applications maybe defined using stackVariables field in stack.json Cluster Variables Any variables that need to be define per cluster maybe declared using clusterVariablesMeta field in stack.json Example: { \"clusterVariablesMeta\" : { \"NEWRELIC_KEY\" : { \"value\" : \"default\" }, \"NEWRELIC_LICENSE_KEY\" : { \"value\" : \"default\" }, \"NEW_RELIC_LICENSE_KEY\" : { \"value\" : \"default\" }, \"NEWRELIC_INSERT_KEY\" : { \"secret\" : true , \"value\" : \"default\" } } } The variables can be set at cluster creation or from the overview page. These variables are injected as environment variables to all application pods. Ingress definitions An ingress may be define by creating a definition in ingress/instances/ directory. Example: Internal ingress/instances/demointernal.json { \"base_domain\" : \"demo.internal\" , \"subdomains\" : [], \"default_ingress\" : false , \"basic_auth_enabled\" : false , \"ingress_rules\" : [], \"internal\" : true } Applications may add ingress rules by adding ingress_rules in their definitions. Eg: \"ingress_rules\" : [ { \"ingress\" : \"demointernal\" , \"path\" : \"/\" , \"targetPort\" : 3000 , \"domainPrefix\" : \"fs.\" } ] This would result in all HTTP traffic to fs.martjack.internal getting directed at the app. External ingress/instances/demoexternal.json { \"base_domain\" : \"demo.facets.cloud\" , \"subdomains\" : [], \"default_ingress\" : true , \"basic_auth_enabled\" : false , \"ingress_rules\" : [], \"internal\" : false } As this is not an external ingress, the domain naming convention is {clusterName}.{base_domain}. The above mentioned ingress rule applied to an external ingress would result in a public endpoint: fs.{clusterName}.demo.facets.cloud","title":"Create a Stack"},{"location":"on_boarding/create_stack/#create-a-stack","text":"By now you must be familiar with the concept of a stack.","title":"Create a stack"},{"location":"on_boarding/create_stack/#git-repository","text":"Create a Github/Bitbucket git repository. To get started, a stack.json file would qualify the repository as a valid stack. { \"clusterVariablesMeta\" : { }, \"stackVariables\" : { } }","title":"Git Repository"},{"location":"on_boarding/create_stack/#register-stack-on-control-plane","text":"Navigate to Create Stack button on the Control Plane and fill in the details.","title":"Register Stack on Control Plane"},{"location":"on_boarding/create_stack/#creating-an-application-definition","text":"An application may be defined by placing a json file in application/instances directory in stack. { \"size\" : \"SMALL\" , \"deploymentStrategy\" : \"RollingUpdate\" , \"elbIdleTimeoutSeconds\" : 300 , \"protocolGroup\" : \"tcp\" , \"scaling\" : { \"hpaEnabled\" : true , \"hpaMinReplicas\" : 1 , \"hpaMaxReplicas\" : 1 , \"hpaMetricThreshold\" : 60 }, \"liveness\" : { \"enableLivenessTCP\" : true , \"livenessPort\" : 8080 , \"livenessInitialDelay\" : 60 , \"livenessTimeout\" : 10 , \"livenessFailureThreshold\" : 20 , \"livenessPeriod\" : 60 , \"livenessSuccessThreshold\" : 1 }, \"readiness\" : { \"enableReadinessTCP\" : true , \"readinessInitialDelay\" : 30 , \"readinessFailureThreshold\" : 8 , \"readinessSuccessThreshold\" : 1 , \"readinessPort\" : 8080 , \"readinessTimeout\" : 10 , \"readinessPeriod\" : 60 }, \"ports\" : [ { \"name\" : \"http\" , \"containerPort\" : 8080 , \"lbPort\" : 80 } ], \"build\" : { \"ci\" : \"deployer\" , \"id\" : \"5e301d0aa4a81300073aba10\" }, \"credentialRequests\" : { \"dbs\" : { \"mysql\" : [ { \"resourceType\" : \"mysql\" , \"resourceName\" : \"billdump\" , \"permission\" : \"READ_WRITE\" , \"environmentVariables\" : [ { \"userName\" : \"INTOUCH_DB_MYSQL_FILESERVICE_USERNAME\" , \"password\" : \"INTOUCH_DB_MYSQL_FILESERVICE_PASSWORD\" } ] } ], \"mongo\" : [] }, \"queues\" : { \"rabbitmq\" : [] }, \"cloud\" : [ { \"resourceType\" : \"s3\" , \"resourceName\" : \"fileservice\" , \"permission\" : \"READ_WRITE\" }, { \"resourceType\" : \"s3\" , \"resourceName\" : \"reon-etl-data\" , \"permission\" : \"READ_WRITE\" }, { \"resourceType\" : \"s3\" , \"resourceName\" : \"campaigns\" , \"permission\" : \"READ_WRITE\" }, { \"resourceType\" : \"s3\" , \"resourceName\" : \"sharingan\" , \"permission\" : \"READ_WRITE\" }, { \"resourceType\" : \"s3\" , \"resourceName\" : \"nsadmindata\" , \"permission\" : \"READ_WRITE\" } ] }, \"environmentVariables\" : { \"static\" : { \"XMX_VALUE\" : \"1573m\" , \"XMS_VALUE\" : \"1573m\" }, \"dynamic\" : { \"FILESERVICE_BUCKET\" : { \"resourceType\" : \"s3\" , \"resourceName\" : \"fileservice\" , \"attribute\" : \"bucket_name\" }, \"CAMPAIGNS_FILESERVICE_BUCKET_NAME\" : { \"resourceType\" : \"s3\" , \"resourceName\" : \"campaigns\" , \"attribute\" : \"bucket_name\" }, \"NSADMINDATA_FILESERVICE_BUCKET_NAME\" : { \"resourceType\" : \"s3\" , \"resourceName\" : \"nsadmindata\" , \"attribute\" : \"bucket_name\" } } }, \"k8s_service_names\" : [ \"fileservice\" ], \"ingress_rules\" : [ { \"ingress\" : \"demoingress\" , \"path\" : \"/\" , \"targetPort\" : 3000 , \"domainPrefix\" : \"fileservice.\" } ], \"resourceAllocationStrategy\" : \"GENERAL_PURPOSE\" }","title":"Creating an Application Definition"},{"location":"on_boarding/create_stack/#size","text":"Pod sizing to use as define in sizing json. ResourceAllocationStrategy drives which sizing family to use.","title":"Size"},{"location":"on_boarding/create_stack/#deployment-strategy","text":"Supported deployment strategies are RollingUpdate and Replace","title":"Deployment Strategy"},{"location":"on_boarding/create_stack/#protocol-group","text":"Protocol groups maybe TCP or UDP","title":"Protocol Group"},{"location":"on_boarding/create_stack/#scaling-configurations","text":"HPA configurations","title":"Scaling Configurations"},{"location":"on_boarding/create_stack/#livelinessreadiness-probes","text":"Liveliness or readiness probes maybe a Port Check, HTTP Probe or a Script probe. The three modes maybe switched by setting the boolean flags enableLivenessTCP, enableLivenessHTTP or enableLivenessEXEC. For Script probe, readinessCommand or livenessCommand arrays define the command to run.","title":"Liveliness/Readiness Probes"},{"location":"on_boarding/create_stack/#ports","text":"Declare the ports","title":"Ports"},{"location":"on_boarding/create_stack/#build-selection","text":"Images are selected based on the ci system (deployer), id of the build job (deployer id), and the release stream selected for the cluster.","title":"Build Selection"},{"location":"on_boarding/create_stack/#credential-management","text":"Credential requests can inject usernames and passwords for databases/queues into environment variables. These users are created dynamically. Cloud credential requests are fulfilled using cloud specific mechanisms (Eg. kube2iam for aws)","title":"Credential Management"},{"location":"on_boarding/create_stack/#static-environment-variables","text":"Static environment variables are tuning parameters like Xmx or threadPool counts. These may be readjusted at a cluster level using overrides from the control plane.","title":"Static Environment Variables"},{"location":"on_boarding/create_stack/#dynamic-environment-variables","text":"Dynamic environment variables may be used to inject attributes of other resources for eg. S3 bucket name, SQS queue name etc into application environment variables.","title":"Dynamic Environment Variables"},{"location":"on_boarding/create_stack/#service-discovery","text":"A Kubernetes service with the same name as the json file name in the default namespace is created. If any specific service name is desired that maybe specified using k8s_service_names","title":"Service Discovery"},{"location":"on_boarding/create_stack/#ingress","text":"An application may be exposed outside the Kubernetes cluster using an ingress. An ingress resource needs to be defined which may be internal (accessible within VPC) or external (accessible via internet). Applications can add rules to direct traffic at them using ingress_rules field in application definition. Rules may be path based or subdomain based. Empty subdomain implies the cluster base domain as defined in the ingress resource is used.","title":"Ingress"},{"location":"on_boarding/create_stack/#application-sizing","text":"The pod sizings to be used can be predefined in a stack. The convention is to have different sizing families viz. CPU_INTENSIVE, GENERAL_PURPOSE etc. The files have to be named: application/sizing.{SIZING_FAMILY}.json Example: application/sizing.CPU_INTENSIVE.json { \"SMALL\" : { \"podCPULimit\" : 1 , \"podMemoryLimit\" : 2 }, \"LARGE\" : { \"podCPULimit\" : 2 , \"podMemoryLimit\" : 4 }, \"XLARGE\" : { \"podCPULimit\" : 3 , \"podMemoryLimit\" : 6 }, \"XXLARGE\" : { \"podCPULimit\" : 6 , \"podMemoryLimit\" : 10 }, \"TINY\" : { \"podCPULimit\" : 0.5 , \"podMemoryLimit\" : 1 }, \"MICRO\" : { \"podCPULimit\" : 0.25 , \"podMemoryLimit\" : 0.5 } }","title":"Application Sizing"},{"location":"on_boarding/create_stack/#common-environment-variables","text":"","title":"Common Environment Variables"},{"location":"on_boarding/create_stack/#stack-variables","text":"Any fixed environment variables that need to be injected into all applications maybe defined using stackVariables field in stack.json","title":"Stack Variables"},{"location":"on_boarding/create_stack/#cluster-variables","text":"Any variables that need to be define per cluster maybe declared using clusterVariablesMeta field in stack.json Example: { \"clusterVariablesMeta\" : { \"NEWRELIC_KEY\" : { \"value\" : \"default\" }, \"NEWRELIC_LICENSE_KEY\" : { \"value\" : \"default\" }, \"NEW_RELIC_LICENSE_KEY\" : { \"value\" : \"default\" }, \"NEWRELIC_INSERT_KEY\" : { \"secret\" : true , \"value\" : \"default\" } } } The variables can be set at cluster creation or from the overview page. These variables are injected as environment variables to all application pods.","title":"Cluster Variables"},{"location":"on_boarding/create_stack/#ingress-definitions","text":"An ingress may be define by creating a definition in ingress/instances/ directory. Example:","title":"Ingress definitions"},{"location":"on_boarding/create_stack/#internal","text":"ingress/instances/demointernal.json { \"base_domain\" : \"demo.internal\" , \"subdomains\" : [], \"default_ingress\" : false , \"basic_auth_enabled\" : false , \"ingress_rules\" : [], \"internal\" : true } Applications may add ingress rules by adding ingress_rules in their definitions. Eg: \"ingress_rules\" : [ { \"ingress\" : \"demointernal\" , \"path\" : \"/\" , \"targetPort\" : 3000 , \"domainPrefix\" : \"fs.\" } ] This would result in all HTTP traffic to fs.martjack.internal getting directed at the app.","title":"Internal"},{"location":"on_boarding/create_stack/#external","text":"ingress/instances/demoexternal.json { \"base_domain\" : \"demo.facets.cloud\" , \"subdomains\" : [], \"default_ingress\" : true , \"basic_auth_enabled\" : false , \"ingress_rules\" : [], \"internal\" : false } As this is not an external ingress, the domain naming convention is {clusterName}.{base_domain}. The above mentioned ingress rule applied to an external ingress would result in a public endpoint: fs.{clusterName}.demo.facets.cloud","title":"External"},{"location":"roadmap/request/","text":"Request a feature Feature requests helps us stay in tune with what customers want, need and expect. Request a feature - info@facets.cloud","title":"Request a feature"},{"location":"roadmap/request/#request-a-feature","text":"Feature requests helps us stay in tune with what customers want, need and expect. Request a feature - info@facets.cloud","title":"Request a feature"},{"location":"roadmap/roadmap/","text":"Roadmap AMJ 2021 Epic Roadmap Jobs To Be Done (JTBD) Extensibility Custom Terraform Modules (GA) Devops teams can write custom TF modules and add to Facets Extensibility Plugin Model (GA) Devops Teams can write a complete facet module and deploy Unified Observability Real Time Log Alerts Developers will receive commonly found log based alerts and custom rules Infosec Enablement Unified Compliance Dashboard Infosec teams can monitor/pull information specific to the compliance needs from a single dashboard Developer Productivity Facets.local distribution mechanism Developers will be able to deploy Facets.local of their FSDL stack locally with a single click Unified Observability Application Custom Metrics Developers can define metric scraping in an easy to define FSDL Deployment Strategies Canary Deployment DevOps can choose Canary deployment as a deployment strategy among others Multi-Cloud Azure Support for Common Infra ( AKS + Blob Developers can deploy a stack on Azure for cloud agnostic components JAS 2021 Epic Roadmap Jobs To Be Done (JTBD) Multi-Cloud Object Storage Gateway Developers can define / use cloud storage like S3 agnostic of the cloud/hybrid/on-prem Customer Request MongoDB Atlas support Developers can run heavy mongo instances on MongoDB Atlas Business Continuity Disaster Recovery Drill Define a backup region during a cluster launch and can perform DR Deployment Strategies Blue-Green Deployment DevOps can choose Blue-Green deployment as a deployment strategy among others Unified Observability Istio deployment DevOps teams can use Istio as a service mesh Customer Request Postgres Integration Developers can use Postgres as a FSDL component with schema management Multi-Cloud Azure Database Service (MySQL), Monitor , app gateway Developers can use cloud native solutions for these services on Azure Multi-Cloud GCP Support for Common Infra ( GKE + GCS ) Developers can deploy a stack on GCP for cloud agnostic components Unified Observability Anomaly Detection Developers can get metric anomaly reports on interested/important metrics OND 2021 Epic Roadmap Jobs To Be Done (JTBD) Research and Exploration Cloud Storage Abstractions Developers can use Cloud Storage Abstractions like ONTAP or opensource alternatives to simplify Stateful operations Cost Facet Cost Leaderboard Attribute Cloud cost to Teams and Modules and create leader boards for cost optimization focus identification Multi-cloud GCP CloudSQL , Cloud Metrics , BigTable Developers can use cloud native solutions for these services on GCP Core Continuous Verification System (GA) Continuously verify the production infrastructure against FSDL stack Unified Observability Index Free Logging Options Developers can choose an Index free logging option like Loki Core Post Deployment Hooks for QA (GA) QA teams can control deployment progress in a CD pipeline Unified Observability Cross Deployment Observability Developers and Devops can compare cross deployment metrics (standard and custom) JFM 2022 Epic Roadmap Jobs To Be Done (JTBD) Multi-cloud Native Support for Mixed Cloud Deveops teams can deploy mixed cloud strategy like Azure + S3 On-prem / Hybrid AWS Outpost Devops teams can manifest a FSDL stack on AWS outposts On-prem / Hybrid Openstack Support Devops teams can manifest a FSDL stack on openstack Infosec Enablement Unified Inventory View Infosec teams can pull inventory of all cloud resources at one place Core Application and Resource View Developers can get details view and history of each resource Extensibility Central Control Plane Events store Devops teams can hook in to Facets CP events and build custom workflows Features Data platforms support Developers can deploy big data pipelines over languages like Apache Spark Customer Requests GPU Support Developers can use GPUs for suitable workloads like ML/Video processing","title":"Roadmap"},{"location":"roadmap/roadmap/#roadmap","text":"","title":"Roadmap"},{"location":"roadmap/roadmap/#amj-2021","text":"Epic Roadmap Jobs To Be Done (JTBD) Extensibility Custom Terraform Modules (GA) Devops teams can write custom TF modules and add to Facets Extensibility Plugin Model (GA) Devops Teams can write a complete facet module and deploy Unified Observability Real Time Log Alerts Developers will receive commonly found log based alerts and custom rules Infosec Enablement Unified Compliance Dashboard Infosec teams can monitor/pull information specific to the compliance needs from a single dashboard Developer Productivity Facets.local distribution mechanism Developers will be able to deploy Facets.local of their FSDL stack locally with a single click Unified Observability Application Custom Metrics Developers can define metric scraping in an easy to define FSDL Deployment Strategies Canary Deployment DevOps can choose Canary deployment as a deployment strategy among others Multi-Cloud Azure Support for Common Infra ( AKS + Blob Developers can deploy a stack on Azure for cloud agnostic components","title":"AMJ 2021"},{"location":"roadmap/roadmap/#jas-2021","text":"Epic Roadmap Jobs To Be Done (JTBD) Multi-Cloud Object Storage Gateway Developers can define / use cloud storage like S3 agnostic of the cloud/hybrid/on-prem Customer Request MongoDB Atlas support Developers can run heavy mongo instances on MongoDB Atlas Business Continuity Disaster Recovery Drill Define a backup region during a cluster launch and can perform DR Deployment Strategies Blue-Green Deployment DevOps can choose Blue-Green deployment as a deployment strategy among others Unified Observability Istio deployment DevOps teams can use Istio as a service mesh Customer Request Postgres Integration Developers can use Postgres as a FSDL component with schema management Multi-Cloud Azure Database Service (MySQL), Monitor , app gateway Developers can use cloud native solutions for these services on Azure Multi-Cloud GCP Support for Common Infra ( GKE + GCS ) Developers can deploy a stack on GCP for cloud agnostic components Unified Observability Anomaly Detection Developers can get metric anomaly reports on interested/important metrics","title":"JAS 2021"},{"location":"roadmap/roadmap/#ond-2021","text":"Epic Roadmap Jobs To Be Done (JTBD) Research and Exploration Cloud Storage Abstractions Developers can use Cloud Storage Abstractions like ONTAP or opensource alternatives to simplify Stateful operations Cost Facet Cost Leaderboard Attribute Cloud cost to Teams and Modules and create leader boards for cost optimization focus identification Multi-cloud GCP CloudSQL , Cloud Metrics , BigTable Developers can use cloud native solutions for these services on GCP Core Continuous Verification System (GA) Continuously verify the production infrastructure against FSDL stack Unified Observability Index Free Logging Options Developers can choose an Index free logging option like Loki Core Post Deployment Hooks for QA (GA) QA teams can control deployment progress in a CD pipeline Unified Observability Cross Deployment Observability Developers and Devops can compare cross deployment metrics (standard and custom)","title":"OND 2021"},{"location":"roadmap/roadmap/#jfm-2022","text":"Epic Roadmap Jobs To Be Done (JTBD) Multi-cloud Native Support for Mixed Cloud Deveops teams can deploy mixed cloud strategy like Azure + S3 On-prem / Hybrid AWS Outpost Devops teams can manifest a FSDL stack on AWS outposts On-prem / Hybrid Openstack Support Devops teams can manifest a FSDL stack on openstack Infosec Enablement Unified Inventory View Infosec teams can pull inventory of all cloud resources at one place Core Application and Resource View Developers can get details view and history of each resource Extensibility Central Control Plane Events store Devops teams can hook in to Facets CP events and build custom workflows Features Data platforms support Developers can deploy big data pipelines over languages like Apache Spark Customer Requests GPU Support Developers can use GPUs for suitable workloads like ML/Video processing","title":"JFM 2022"},{"location":"tools/compliance/","text":"Compliance and Security Controls Facets.cloud encourages secure practices and out of the box security tools. This enables any cluster launched through facets.cloud to be easier for compliance with minimal involvement of technology team in the process. Facets.cloud doesn't provide any proprietary tools for security rather aim to integrate with existing opensource and paid tool options. The scope of the compliance here is the cloud security parts only that is launched and managed by facets.cloud Depending on the industry you operate in, the following standards may be applicable to you * ISO * PCI DSS * SOC-2 Broadly, the cloud security scope falls into the following areas Infrastructure Security Practices Deployment of Facets.cloud Facets.cloud is deployed on the customer's premises as a licensed solution. It is recommended that this is deployed in a standalone AWS account following AWS Organizations best practices. This excludes any thirdparty infrastructure to come additionally in the security and complaince scope. High level deployment model Any cluster deployed through Facets.cloud follows best practices recommended by the cloud vendor. For e.g., in the case of AWS, the underlying infrastructure contains an EKS cluster hosted inside private subnet of a VPC. By default, there is no direct connectivity to the EKS cluster from outside unless an application explicitly specifies it. This specification if provided, goes through the Stack definition of the application and hence checked in a git repository. Apart from the advantages of this practice being declarative in nature, specific to security and compliance, it provides the following advantages - * Named (Who created/updated it) * Version controlled * Process controlled (Secondary sign-off using PR Reviews) * easily auditable Antivirus (HIDS) ClamAV are installed in every node launched by Facets. Facets is responsible for updating and ensuring the ClamAV agents are running all the time. ClamAV antivirus scan results are pushed to a permanent storage from which the results can be downloaded. In future, these results will be available in SIEM dashboard as well. Security Information and Event Management (SIEM) Facets.cloud comes with pre-integration with Falco . Falco provides the cloud-native runtime security and is the de-facto Kubernetes threat detection engine. Falco ships with a default set of rules that check the kernel for unusual behaviors. Read the falco features here . Any cluster launched by Facets contains prometheus and grafana by default. Falco output metrics are parsed and sent to prometheus for the infromation security team to monitor and custommize the standard dashboards provided by Facets. Additionally, if a paid tool like Newrelic is enabled, these metrics automatically gets pushed to Newrelic for a cluster-wide view. Firewall (NIDS) A cloud launched by Facets will have ModSecurity installed at the ingress points. Any application developer who wants to expose a web server port to the outside world must define an ingress rule in the application stack definition. Facets injects ModSecurity with OWASP ModSecurity Core Rule Set . Similar to Falco, the output is sent to prometheus/grafana and can be optionally relayed to third party monitoring tools like Newrelic as well. An information Security personnel can customize the rules for alerting. Security Practices Network, Security and IAM All resources are provisioned by Facets during the cluster launch and update based on CredentialRequests. The credentials requested by any application is only available to that application. QA, Stage and production environments are created separately in Facets with share nothing principles. All physical resources are created in private subnet of the VPC and only uses a NAT gateway for outbound traffic By default, no network traffic is allowed to the network with deny-all policies. Any application that needs an ingress route is injected by a ModSecurity WAF. This is as per the DMZ (De-Militarized Zone) best practices. Secrets, Encryption and Key management Database, Cloud resource secrets are requested by the applications in the stack definitions and fulfilled by facets at the cluster launch. This eliminates any need of a manual password or access creation that can potentially expose risk of leakage. All PVCs are encrypted and cloud-native databases like Aurora are provisioned with the best practice security policies like encryption at rest . Certificate management happpens on the cloud provider like AWS Certificate Manager ( ACM ) and required SSL and TLS configurations adopted that are recommended by the cloud provider. Access Control Just in time, temporary credentials are issued in the Facets control plane for anyone who wants to access the kubernetes cluster for maintenance activities. This token expires in 24 hours. The user privileges are controlled by the admins of Facets control plane. Any management port that is required to be exposed by the application/service uses a tools ingress that is password protected. Facets comes with pre-integration with Zero trust Application Access systems such as Cloudflare Access .","title":"Compliance & Security"},{"location":"tools/compliance/#compliance-and-security-controls","text":"Facets.cloud encourages secure practices and out of the box security tools. This enables any cluster launched through facets.cloud to be easier for compliance with minimal involvement of technology team in the process. Facets.cloud doesn't provide any proprietary tools for security rather aim to integrate with existing opensource and paid tool options. The scope of the compliance here is the cloud security parts only that is launched and managed by facets.cloud Depending on the industry you operate in, the following standards may be applicable to you * ISO * PCI DSS * SOC-2 Broadly, the cloud security scope falls into the following areas","title":"Compliance and Security Controls"},{"location":"tools/compliance/#infrastructure-security-practices","text":"","title":"Infrastructure Security Practices"},{"location":"tools/compliance/#deployment-of-facetscloud","text":"Facets.cloud is deployed on the customer's premises as a licensed solution. It is recommended that this is deployed in a standalone AWS account following AWS Organizations best practices. This excludes any thirdparty infrastructure to come additionally in the security and complaince scope.","title":"Deployment of Facets.cloud"},{"location":"tools/compliance/#high-level-deployment-model","text":"Any cluster deployed through Facets.cloud follows best practices recommended by the cloud vendor. For e.g., in the case of AWS, the underlying infrastructure contains an EKS cluster hosted inside private subnet of a VPC. By default, there is no direct connectivity to the EKS cluster from outside unless an application explicitly specifies it. This specification if provided, goes through the Stack definition of the application and hence checked in a git repository. Apart from the advantages of this practice being declarative in nature, specific to security and compliance, it provides the following advantages - * Named (Who created/updated it) * Version controlled * Process controlled (Secondary sign-off using PR Reviews) * easily auditable","title":"High level deployment model"},{"location":"tools/compliance/#antivirus-hids","text":"ClamAV are installed in every node launched by Facets. Facets is responsible for updating and ensuring the ClamAV agents are running all the time. ClamAV antivirus scan results are pushed to a permanent storage from which the results can be downloaded. In future, these results will be available in SIEM dashboard as well.","title":"Antivirus (HIDS)"},{"location":"tools/compliance/#security-information-and-event-management-siem","text":"Facets.cloud comes with pre-integration with Falco . Falco provides the cloud-native runtime security and is the de-facto Kubernetes threat detection engine. Falco ships with a default set of rules that check the kernel for unusual behaviors. Read the falco features here . Any cluster launched by Facets contains prometheus and grafana by default. Falco output metrics are parsed and sent to prometheus for the infromation security team to monitor and custommize the standard dashboards provided by Facets. Additionally, if a paid tool like Newrelic is enabled, these metrics automatically gets pushed to Newrelic for a cluster-wide view.","title":"Security Information and Event Management (SIEM)"},{"location":"tools/compliance/#firewall-nids","text":"A cloud launched by Facets will have ModSecurity installed at the ingress points. Any application developer who wants to expose a web server port to the outside world must define an ingress rule in the application stack definition. Facets injects ModSecurity with OWASP ModSecurity Core Rule Set . Similar to Falco, the output is sent to prometheus/grafana and can be optionally relayed to third party monitoring tools like Newrelic as well. An information Security personnel can customize the rules for alerting.","title":"Firewall (NIDS)"},{"location":"tools/compliance/#security-practices","text":"","title":"Security Practices"},{"location":"tools/compliance/#network-security-and-iam","text":"All resources are provisioned by Facets during the cluster launch and update based on CredentialRequests. The credentials requested by any application is only available to that application. QA, Stage and production environments are created separately in Facets with share nothing principles. All physical resources are created in private subnet of the VPC and only uses a NAT gateway for outbound traffic By default, no network traffic is allowed to the network with deny-all policies. Any application that needs an ingress route is injected by a ModSecurity WAF. This is as per the DMZ (De-Militarized Zone) best practices.","title":"Network, Security and IAM"},{"location":"tools/compliance/#secrets-encryption-and-key-management","text":"Database, Cloud resource secrets are requested by the applications in the stack definitions and fulfilled by facets at the cluster launch. This eliminates any need of a manual password or access creation that can potentially expose risk of leakage. All PVCs are encrypted and cloud-native databases like Aurora are provisioned with the best practice security policies like encryption at rest . Certificate management happpens on the cloud provider like AWS Certificate Manager ( ACM ) and required SSL and TLS configurations adopted that are recommended by the cloud provider.","title":"Secrets, Encryption and Key management"},{"location":"tools/compliance/#access-control","text":"Just in time, temporary credentials are issued in the Facets control plane for anyone who wants to access the kubernetes cluster for maintenance activities. This token expires in 24 hours. The user privileges are controlled by the admins of Facets control plane. Any management port that is required to be exposed by the application/service uses a tools ingress that is password protected. Facets comes with pre-integration with Zero trust Application Access systems such as Cloudflare Access .","title":"Access Control"},{"location":"tools/observability/","text":"Observability The following are usually the three levers to build in-depth observability to your application deployments in production environment * Metrics * Logs * Tracing Metrics The deployments created through Facets ships with a built-in Grafana and Prometheus set up with pre-integrations to standard components and relevant dashboards. The Grafana dashboard can be accessed through the control plane or with cluster specific URLs by the develops, devops and support staff. The metrics collected by Prometheus are usually of the following types * Infrastructure Metrics (Pre-built metric exporters) * Application Metrics ( Open telemetry ) Infrastructure Metrics Any components instantiated through Facets comes with the relevant pre-built metrics dashboards. The following graphs shows a pre-built redis dashboard. Application Metrics Facets.cloud adopts Open Telemetry standards for pushing metrics. Applications expose metrics as end-points and declare it as a monitoring object inside the FSDL application specifications. Facets.cloud instruments the scraping of these metrics out of the application metrics end-points and submits to Prometheus. User Defined Dashboards Dashboards can also be defined in Facet stack definition language by committing the exported json from grafana into the stack definition place the json file in /dashboards/instances directory in your stack Metrics Integrations with third party tools You can use your favourite third-party tools like Newrelic to visualize the metrics apart from the Grafana dashboard. The Newrelic pre-integration relays metrics from prometheus to Newrelic without any other code change to the application. Add NEWRELIC_LICENSE_KEY to the Common Environment Variables to enable the pre-integration. The following shows the earlier redis dashboard on newrelic. Logs Facets expects all application containers to log to system.out . For most languages, this can be achieved by using a console appender to the code. Facets uses fluentd to relay logs and presents various options of log collection. NFS with object storage as backup This option usually translates to an EFS with S3 if the deployment is on AWS cloud. This option by default acts as the source of truth of all the log storage at a single place. The logs are organized as folders in application/containers and get pushed to S3 at configured time interval.The logs can be accessed through a Wetty terminal after a required authorization by the user. Older logs can be downloaded from s3 on need-basis on the same console. Additional logging substacks ELK - Additional to EFS/NFS as logging, an ELK substack can be chosen to index and search the logs. Depending on the log volumes produced by the applications per-day, this may be an effective solution More log collection options are in development .. Traces Facets doesn't provide any tracing integrations yet. Tracing is usually instrumented inside the application code. Alerts All active and inactive alerts can be obtained through Alerts dropdown in the control plane. The set of alerts can be categorized in to two parts 1. Standard Alerts - Facets ships standard alerts with each component that is defined in the stack. 2. User defined Alerts - Additionally, alerts can be defined in PromQL and committed in the stack git repo, which will be automatically available in all deployments These Alerts can be defined in Facet stack definition language by committing the alertmanager yaml into the stack definition place the yaml file in /alerts/instances directory in your stack Sample Yaml File: - name: mongo.rules rules: - alert: MongoRelicaStatusSecondaryCrit expr: mongodb_mongod_replset_member_state{state=\"SECONDARY\"} != 2 for: 2m labels: severity: critical team: infra resourceType: mongo resourceName: \"{{ $labels.pod_name }}\" annotations: message: MongoDB secondary replica status down The alerts can be pushed to ChatOPs tools like Slack or flock. Any team that has added the corresponding module as an observer, receives the alert for that module by the channel updates.","title":"Observability"},{"location":"tools/observability/#observability","text":"The following are usually the three levers to build in-depth observability to your application deployments in production environment * Metrics * Logs * Tracing","title":"Observability"},{"location":"tools/observability/#metrics","text":"The deployments created through Facets ships with a built-in Grafana and Prometheus set up with pre-integrations to standard components and relevant dashboards. The Grafana dashboard can be accessed through the control plane or with cluster specific URLs by the develops, devops and support staff. The metrics collected by Prometheus are usually of the following types * Infrastructure Metrics (Pre-built metric exporters) * Application Metrics ( Open telemetry )","title":"Metrics"},{"location":"tools/observability/#infrastructure-metrics","text":"Any components instantiated through Facets comes with the relevant pre-built metrics dashboards. The following graphs shows a pre-built redis dashboard.","title":"Infrastructure Metrics"},{"location":"tools/observability/#application-metrics","text":"Facets.cloud adopts Open Telemetry standards for pushing metrics. Applications expose metrics as end-points and declare it as a monitoring object inside the FSDL application specifications. Facets.cloud instruments the scraping of these metrics out of the application metrics end-points and submits to Prometheus.","title":"Application Metrics"},{"location":"tools/observability/#user-defined-dashboards","text":"Dashboards can also be defined in Facet stack definition language by committing the exported json from grafana into the stack definition place the json file in /dashboards/instances directory in your stack","title":"User Defined Dashboards"},{"location":"tools/observability/#metrics-integrations-with-third-party-tools","text":"You can use your favourite third-party tools like Newrelic to visualize the metrics apart from the Grafana dashboard. The Newrelic pre-integration relays metrics from prometheus to Newrelic without any other code change to the application. Add NEWRELIC_LICENSE_KEY to the Common Environment Variables to enable the pre-integration. The following shows the earlier redis dashboard on newrelic.","title":"Metrics Integrations with third party tools"},{"location":"tools/observability/#logs","text":"Facets expects all application containers to log to system.out . For most languages, this can be achieved by using a console appender to the code. Facets uses fluentd to relay logs and presents various options of log collection.","title":"Logs"},{"location":"tools/observability/#nfs-with-object-storage-as-backup","text":"This option usually translates to an EFS with S3 if the deployment is on AWS cloud. This option by default acts as the source of truth of all the log storage at a single place. The logs are organized as folders in application/containers and get pushed to S3 at configured time interval.The logs can be accessed through a Wetty terminal after a required authorization by the user. Older logs can be downloaded from s3 on need-basis on the same console.","title":"NFS with object storage as backup"},{"location":"tools/observability/#additional-logging-substacks","text":"ELK - Additional to EFS/NFS as logging, an ELK substack can be chosen to index and search the logs. Depending on the log volumes produced by the applications per-day, this may be an effective solution More log collection options are in development ..","title":"Additional logging substacks"},{"location":"tools/observability/#traces","text":"Facets doesn't provide any tracing integrations yet. Tracing is usually instrumented inside the application code.","title":"Traces"},{"location":"tools/observability/#alerts","text":"All active and inactive alerts can be obtained through Alerts dropdown in the control plane. The set of alerts can be categorized in to two parts 1. Standard Alerts - Facets ships standard alerts with each component that is defined in the stack. 2. User defined Alerts - Additionally, alerts can be defined in PromQL and committed in the stack git repo, which will be automatically available in all deployments These Alerts can be defined in Facet stack definition language by committing the alertmanager yaml into the stack definition place the yaml file in /alerts/instances directory in your stack Sample Yaml File: - name: mongo.rules rules: - alert: MongoRelicaStatusSecondaryCrit expr: mongodb_mongod_replset_member_state{state=\"SECONDARY\"} != 2 for: 2m labels: severity: critical team: infra resourceType: mongo resourceName: \"{{ $labels.pod_name }}\" annotations: message: MongoDB secondary replica status down The alerts can be pushed to ChatOPs tools like Slack or flock. Any team that has added the corresponding module as an observer, receives the alert for that module by the channel updates.","title":"Alerts"}]}
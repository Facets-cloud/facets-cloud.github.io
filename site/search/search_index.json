{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"About Facets.cloud Facets.cloud is a cloud automation platform for Developers and DevSecOps. Facets.cloud simplifies provisioning and change management of applications, infrastructure components and databases on multiple cloud platforms. Salient Features Any deployment provisioned through Facets.cloud automatically gets continuous deployments, observability, Security practices and disaster recovery features. 1. Declarative Provisioning Define your complete product stack (blueprint) in an easy to write Facets.cloud Stack Definition Language (JSON). The blueprint contains application definitions, cloud resources, database specifications and the dependencies between them. The blueprint is version/access controlled and any number of deployments can be manifested out of it. These deployments can be QA, Staging, Load Test or multiple production environments on different cloud providers. 2. Continuous Mutations Once deployed through Facets.cloud, the entire deployment can receive continuous mutations. These mutations can be regular application releases integrated with the CI systems or can be changes to resources like Databases, queues and their properties. Facets.cloud ensures that all changes are consistently deployed across all deployments of the stack. 3. Optimized cloud cost Any deployment provisioned through Facets.cloud gets the best practice implementation for auto-scaling, spot utilization for optimal cloud spend. Additionally, since all resources and their dependencies are accounted for in the blueprint, the cost leakage is minimized. 4. Observability First Facets.cloud components are developed with observability first approach. Infrastructure, application and cloud resource metrics get aggregated and pre-built dashboards and well-researched alerts are auto-configured. The alerts are pushed to chat-ops tools and custom notification channels. 5. Built-in Security and compliance Deployments receive best practice point-to-site connectivity for developers and devops with role based access control. Networks, Security, SSL certificates are auto provisioned and managed by Facets. Antivirus, OSSEC tools come built-in with pre-built dashboards for monitoring and compliance. Facets.cloud ensures all critical components like Databases are backed by a disaster recovery solution. How is Facets.cloud built? Facets.cloud is built on open standards like Kubernetes, Open Telemetry. It leverages the best of the offerings of the cloud providers by being cloud native and at the same time supports multiple cloud platforms and local development environments. Please find a demonstration of a sample application deployment here . About the Company Facets.cloud is an independent entity that is incubated under Capillary Technologies , a leading SaaS product in the customer engagement sector. Currently, it manages applications hosted on several thousands of nodes provisioned on AWS public cloud. Facets.cloud has helped in reducing 15% of production issues emerging from automation gaps. Key Terminologies Stack - Stack is a blueprint that defines the components of a Product (Microservices, infrastructure) and relationships between them. Cluster - Cluster is the physical manifestation of the stack in a cloud like AWS. One stack can have many clusters like QA, Pre prod, Production 1, Production 2 etc. Control Plane - Control plane is a UI for defining deploying and managing stacks and clusters. This UI is private to each customer and can be used to deploy multiple stacks and clusters. Watch Facets in Action A sample deployment","title":"Home"},{"location":"#about-facetscloud","text":"Facets.cloud is a cloud automation platform for Developers and DevSecOps. Facets.cloud simplifies provisioning and change management of applications, infrastructure components and databases on multiple cloud platforms.","title":"About Facets.cloud"},{"location":"#salient-features","text":"Any deployment provisioned through Facets.cloud automatically gets continuous deployments, observability, Security practices and disaster recovery features. 1. Declarative Provisioning Define your complete product stack (blueprint) in an easy to write Facets.cloud Stack Definition Language (JSON). The blueprint contains application definitions, cloud resources, database specifications and the dependencies between them. The blueprint is version/access controlled and any number of deployments can be manifested out of it. These deployments can be QA, Staging, Load Test or multiple production environments on different cloud providers. 2. Continuous Mutations Once deployed through Facets.cloud, the entire deployment can receive continuous mutations. These mutations can be regular application releases integrated with the CI systems or can be changes to resources like Databases, queues and their properties. Facets.cloud ensures that all changes are consistently deployed across all deployments of the stack. 3. Optimized cloud cost Any deployment provisioned through Facets.cloud gets the best practice implementation for auto-scaling, spot utilization for optimal cloud spend. Additionally, since all resources and their dependencies are accounted for in the blueprint, the cost leakage is minimized. 4. Observability First Facets.cloud components are developed with observability first approach. Infrastructure, application and cloud resource metrics get aggregated and pre-built dashboards and well-researched alerts are auto-configured. The alerts are pushed to chat-ops tools and custom notification channels. 5. Built-in Security and compliance Deployments receive best practice point-to-site connectivity for developers and devops with role based access control. Networks, Security, SSL certificates are auto provisioned and managed by Facets. Antivirus, OSSEC tools come built-in with pre-built dashboards for monitoring and compliance. Facets.cloud ensures all critical components like Databases are backed by a disaster recovery solution.","title":"Salient Features"},{"location":"#how-is-facetscloud-built","text":"Facets.cloud is built on open standards like Kubernetes, Open Telemetry. It leverages the best of the offerings of the cloud providers by being cloud native and at the same time supports multiple cloud platforms and local development environments. Please find a demonstration of a sample application deployment here .","title":"How is Facets.cloud built?"},{"location":"#about-the-company","text":"Facets.cloud is an independent entity that is incubated under Capillary Technologies , a leading SaaS product in the customer engagement sector. Currently, it manages applications hosted on several thousands of nodes provisioned on AWS public cloud. Facets.cloud has helped in reducing 15% of production issues emerging from automation gaps.","title":"About the Company"},{"location":"#key-terminologies","text":"Stack - Stack is a blueprint that defines the components of a Product (Microservices, infrastructure) and relationships between them. Cluster - Cluster is the physical manifestation of the stack in a cloud like AWS. One stack can have many clusters like QA, Pre prod, Production 1, Production 2 etc. Control Plane - Control plane is a UI for defining deploying and managing stacks and clusters. This UI is private to each customer and can be used to deploy multiple stacks and clusters.","title":"Key Terminologies"},{"location":"#watch-facets-in-action","text":"A sample deployment","title":"Watch Facets in Action"},{"location":"getting_started/demo/","text":"Demo Awesomeness Inc. is a company having two product suites \u201cS3 file uploader\u201d and \u201cTodo App\u201d. S3 uploader application needs to be deployed in a VPC and has various components to it. Todo app too needs a separate VPC and has couple of microservices and database in it. Awesomeness Inc. is a Facets customer and has its own control plane. We will sit through the company's journey of creation of these stacks in Facets product. Demo Video","title":"Demo"},{"location":"getting_started/demo/#demo","text":"Awesomeness Inc. is a company having two product suites \u201cS3 file uploader\u201d and \u201cTodo App\u201d. S3 uploader application needs to be deployed in a VPC and has various components to it. Todo app too needs a separate VPC and has couple of microservices and database in it. Awesomeness Inc. is a Facets customer and has its own control plane. We will sit through the company's journey of creation of these stacks in Facets product.","title":"Demo"},{"location":"getting_started/demo/#demo-video","text":"","title":"Demo Video"},{"location":"getting_started/prerequisites/","text":"Onboarding Applications to facets. In order to migrate your applications to Facets we would need them to be dockerized and ready for kubernetes deployments. Following are few guidelines to follow while containerising your applications or readying your existing containers. Checkout the best practices for creating a docker image here and here Logging: Applications must log into stdout/stderr and not files. Read here for java application Environment Variables: Use environment variables for reading all database usernames and passwords in your applications. This will later help us auto-wire these details and manage credential management for you once you are on Facets. Use environment variables to refer to any cloud resource like S3, SQS or SNS. Facets can then dynamically fulfil these variables. AWS SDK (If Used): Use AWS keys and secrets in your applications via environment variables, rather use the default credential provider. This will enable auto provision the IAM for your application and have seamless access to resources it has requested Details here . Image Registry: Use either dockerhub private registry or Amazon Elastic Container Registry (Amazon ECR) for storing your docker images. Facets has support for onboarding these registries and can pull images from here. Service Discovery: Use either DNS or IP based service discovery via environment variables for communication between services and/ or databases easier. This will enable easy porting into kubernetes on Facets. Readiness and Liveliness checks: Readiness and Liveliness checks are important and should be configured appropriately to keep your application well managed. Read here for more details","title":"Prerequisites"},{"location":"getting_started/prerequisites/#onboarding-applications-to-facets","text":"In order to migrate your applications to Facets we would need them to be dockerized and ready for kubernetes deployments. Following are few guidelines to follow while containerising your applications or readying your existing containers. Checkout the best practices for creating a docker image here and here","title":"Onboarding Applications to facets."},{"location":"getting_started/prerequisites/#logging","text":"Applications must log into stdout/stderr and not files. Read here for java application","title":"Logging:"},{"location":"getting_started/prerequisites/#environment-variables","text":"Use environment variables for reading all database usernames and passwords in your applications. This will later help us auto-wire these details and manage credential management for you once you are on Facets. Use environment variables to refer to any cloud resource like S3, SQS or SNS. Facets can then dynamically fulfil these variables.","title":"Environment Variables:"},{"location":"getting_started/prerequisites/#aws-sdk-if-used","text":"Use AWS keys and secrets in your applications via environment variables, rather use the default credential provider. This will enable auto provision the IAM for your application and have seamless access to resources it has requested Details here .","title":"AWS SDK (If Used):"},{"location":"getting_started/prerequisites/#image-registry","text":"Use either dockerhub private registry or Amazon Elastic Container Registry (Amazon ECR) for storing your docker images. Facets has support for onboarding these registries and can pull images from here.","title":"Image Registry:"},{"location":"getting_started/prerequisites/#service-discovery","text":"Use either DNS or IP based service discovery via environment variables for communication between services and/ or databases easier. This will enable easy porting into kubernetes on Facets.","title":"Service Discovery:"},{"location":"getting_started/prerequisites/#readiness-and-liveliness-checks","text":"Readiness and Liveliness checks are important and should be configured appropriately to keep your application well managed. Read here for more details","title":"Readiness and Liveliness checks:"},{"location":"roadmap/request/","text":"Request a feature Feature requests helps us stay in tune with what customers want, need and expect. Request a feature - info@facets.cloud","title":"Request a feature"},{"location":"roadmap/request/#request-a-feature","text":"Feature requests helps us stay in tune with what customers want, need and expect. Request a feature - info@facets.cloud","title":"Request a feature"},{"location":"roadmap/roadmap/","text":"Roadmap AMJ 2021 Epic Roadmap Jobs To Be Done (JTBD) Extensibility Custom Terraform Modules (GA) Devops teams can write custom TF modules and add to Facets Extensibility Plugin Model (GA) Devops Teams can write a complete facet module and deploy Unified Observability Real Time Log Alerts Developers will receive commonly found log based alerts and custom rules Infosec Enablement Unified Compliance Dashboard Infosec teams can monitor/pull information specific to the compliance needs from a single dashboard Developer Productivity Facets.local distribution mechanism Developers will be able to deploy Facets.local of their FSDL stack locally with a single click Unified Observability Application Custom Metrics Developers can define metric scraping in an easy to define FSDL Deployment Strategies Canary Deployment DevOps can choose Canary deployment as a deployment strategy among others Multi-Cloud Azure Support for Common Infra ( AKS + Blob Developers can deploy a stack on Azure for cloud agnostic components JAS 2021 Epic Roadmap Jobs To Be Done (JTBD) Multi-Cloud Object Storage Gateway Developers can define / use cloud storage like S3 agnostic of the cloud/hybrid/on-prem Customer Request MongoDB Atlas support Developers can run heavy mongo instances on MongoDB Atlas Business Continuity Disaster Recovery Drill Define a backup region during a cluster launch and can perform DR Deployment Strategies Blue-Green Deployment DevOps can choose Blue-Green deployment as a deployment strategy among others Unified Observability Istio deployment DevOps teams can use Istio as a service mesh Customer Request Postgres Integration Developers can use Postgres as a FSDL component with schema management Multi-Cloud Azure Database Service (MySQL), Monitor , app gateway Developers can use cloud native solutions for these services on Azure Multi-Cloud GCP Support for Common Infra ( GKE + GCS ) Developers can deploy a stack on GCP for cloud agnostic components Unified Observability Anomaly Detection Developers can get metric anomaly reports on interested/important metrics OND 2021 Epic Roadmap Jobs To Be Done (JTBD) Research and Exploration Cloud Storage Abstractions Developers can use Cloud Storage Abstractions like ONTAP or opensource alternatives to simplify Stateful operations Cost Facet Cost Leaderboard Attribute Cloud cost to Teams and Modules and create leader boards for cost optimization focus identification Multi-cloud GCP CloudSQL , Cloud Metrics , BigTable Developers can use cloud native solutions for these services on GCP Core Continuous Verification System (GA) Continuously verify the production infrastructure against FSDL stack Unified Observability Index Free Logging Options Developers can choose an Index free logging option like Loki Core Post Deployment Hooks for QA (GA) QA teams can control deployment progress in a CD pipeline Unified Observability Cross Deployment Observability Developers and Devops can compare cross deployment metrics (standard and custom) JFM 2022 Epic Roadmap Jobs To Be Done (JTBD) Multi-cloud Native Support for Mixed Cloud Deveops teams can deploy mixed cloud strategy like Azure + S3 On-prem / Hybrid AWS Outpost Devops teams can manifest a FSDL stack on AWS outposts On-prem / Hybrid Openstack Support Devops teams can manifest a FSDL stack on openstack Infosec Enablement Unified Inventory View Infosec teams can pull inventory of all cloud resources at one place Core Application and Resource View Developers can get details view and history of each resource Extensibility Central Control Plane Events store Devops teams can hook in to Facets CP events and build custom workflows Features Data platforms support Developers can deploy big data pipelines over languages like Apache Spark Customer Requests GPU Support Developers can use GPUs for suitable workloads like ML/Video processing","title":"Roadmap"},{"location":"roadmap/roadmap/#roadmap","text":"","title":"Roadmap"},{"location":"roadmap/roadmap/#amj-2021","text":"Epic Roadmap Jobs To Be Done (JTBD) Extensibility Custom Terraform Modules (GA) Devops teams can write custom TF modules and add to Facets Extensibility Plugin Model (GA) Devops Teams can write a complete facet module and deploy Unified Observability Real Time Log Alerts Developers will receive commonly found log based alerts and custom rules Infosec Enablement Unified Compliance Dashboard Infosec teams can monitor/pull information specific to the compliance needs from a single dashboard Developer Productivity Facets.local distribution mechanism Developers will be able to deploy Facets.local of their FSDL stack locally with a single click Unified Observability Application Custom Metrics Developers can define metric scraping in an easy to define FSDL Deployment Strategies Canary Deployment DevOps can choose Canary deployment as a deployment strategy among others Multi-Cloud Azure Support for Common Infra ( AKS + Blob Developers can deploy a stack on Azure for cloud agnostic components","title":"AMJ 2021"},{"location":"roadmap/roadmap/#jas-2021","text":"Epic Roadmap Jobs To Be Done (JTBD) Multi-Cloud Object Storage Gateway Developers can define / use cloud storage like S3 agnostic of the cloud/hybrid/on-prem Customer Request MongoDB Atlas support Developers can run heavy mongo instances on MongoDB Atlas Business Continuity Disaster Recovery Drill Define a backup region during a cluster launch and can perform DR Deployment Strategies Blue-Green Deployment DevOps can choose Blue-Green deployment as a deployment strategy among others Unified Observability Istio deployment DevOps teams can use Istio as a service mesh Customer Request Postgres Integration Developers can use Postgres as a FSDL component with schema management Multi-Cloud Azure Database Service (MySQL), Monitor , app gateway Developers can use cloud native solutions for these services on Azure Multi-Cloud GCP Support for Common Infra ( GKE + GCS ) Developers can deploy a stack on GCP for cloud agnostic components Unified Observability Anomaly Detection Developers can get metric anomaly reports on interested/important metrics","title":"JAS 2021"},{"location":"roadmap/roadmap/#ond-2021","text":"Epic Roadmap Jobs To Be Done (JTBD) Research and Exploration Cloud Storage Abstractions Developers can use Cloud Storage Abstractions like ONTAP or opensource alternatives to simplify Stateful operations Cost Facet Cost Leaderboard Attribute Cloud cost to Teams and Modules and create leader boards for cost optimization focus identification Multi-cloud GCP CloudSQL , Cloud Metrics , BigTable Developers can use cloud native solutions for these services on GCP Core Continuous Verification System (GA) Continuously verify the production infrastructure against FSDL stack Unified Observability Index Free Logging Options Developers can choose an Index free logging option like Loki Core Post Deployment Hooks for QA (GA) QA teams can control deployment progress in a CD pipeline Unified Observability Cross Deployment Observability Developers and Devops can compare cross deployment metrics (standard and custom)","title":"OND 2021"},{"location":"roadmap/roadmap/#jfm-2022","text":"Epic Roadmap Jobs To Be Done (JTBD) Multi-cloud Native Support for Mixed Cloud Deveops teams can deploy mixed cloud strategy like Azure + S3 On-prem / Hybrid AWS Outpost Devops teams can manifest a FSDL stack on AWS outposts On-prem / Hybrid Openstack Support Devops teams can manifest a FSDL stack on openstack Infosec Enablement Unified Inventory View Infosec teams can pull inventory of all cloud resources at one place Core Application and Resource View Developers can get details view and history of each resource Extensibility Central Control Plane Events store Devops teams can hook in to Facets CP events and build custom workflows Features Data platforms support Developers can deploy big data pipelines over languages like Apache Spark Customer Requests GPU Support Developers can use GPUs for suitable workloads like ML/Video processing","title":"JFM 2022"},{"location":"tools/compliance/","text":"Compliance and Security Controls Facets.cloud encourages secure practices and out of the box security tools. This enables any cluster launched through facets.cloud to be easier for compliance with minimal involvement of technology team in the process. Facets.cloud doesn't provide any proprietary tools for security rather aim to integrate with existing opensource and paid tool options. The scope of the compliance here is the cloud security parts only that is launched and managed by facets.cloud Depending on the industry you operate in, the following standards may be applicable to you * ISO * PCI DSS * SOC-2 Broadly, the cloud security scope falls into the following areas Infrastructure Security Practices Deployment of Facets.cloud Facets.cloud is deployed on the customer's premises as a licensed solution. It is recommended that this is deployed in a standalone AWS account following AWS Organizations best practices. This excludes any thirdparty infrastructure to come additionally in the security and complaince scope. High level deployment model Any cluster deployed through Facets.cloud follows best practices recommended by the cloud vendor. For e.g., in the case of AWS, the underlying infrastructure contains an EKS cluster hosted inside private subnet of a VPC. By default, there is no direct connectivity to the EKS cluster from outside unless an application explicitly specifies it. This specification if provided, goes through the Stack definition of the application and hence checked in a git repository. Apart from the advantages of this practice being declarative in nature, specific to security and compliance, it provides the following advantages - * Named (Who created/updated it) * Version controlled * Process controlled (Secondary sign-off using PR Reviews) * easily auditable Antivirus (HIDS) ClamAV are installed in every node launched by Facets. Facets is responsible for updating and ensuring the ClamAV agents are running all the time. ClamAV antivirus scan results are pushed to a permanent storage from which the results can be downloaded. In future, these results will be available in SIEM dashboard as well. Security Information and Event Management (SIEM) Facets.cloud comes with pre-integration with Falco . Falco provides the cloud-native runtime security and is the de-facto Kubernetes threat detection engine. Falco ships with a default set of rules that check the kernel for unusual behaviors. Read the falco features here . Any cluster launched by Facets contains prometheus and grafana by default. Falco output metrics are parsed and sent to prometheus for the infromation security team to monitor and custommize the standard dashboards provided by Facets. Additionally, if a paid tool like Newrelic is enabled, these metrics automatically gets pushed to Newrelic for a cluster-wide view. Firewall (NIDS) A cloud launched by Facets will have ModSecurity installed at the ingress points. Any application developer who wants to expose a web server port to the outside world must define an ingress rule in the application stack definition. Facets injects ModSecurity with OWASP ModSecurity Core Rule Set . Similar to Falco, the output is sent to prometheus/grafana and can be optionally relayed to third party monitoring tools like Newrelic as well. An information Security personnel can customize the rules for alerting. Security Practices Network, Security and IAM All resources are provisioned by Facets during the cluster launch and update based on CredentialRequests. The credentials requested by any application is only available to that application. QA, Stage and production environments are created separately in Facets with share nothing principles. All physical resources are created in private subnet of the VPC and only uses a NAT gateway for outbound traffic By default, no network traffic is allowed to the network with deny-all policies. Any application that needs an ingress route is injected by a ModSecurity WAF. This is as per the DMZ (De-Militarized Zone) best practices. Secrets, Encryption and Key management Database, Cloud resource secrets are requested by the applications in the stack definitions and fulfilled by facets at the cluster launch. This eliminates any need of a manual password or access creation that can potentially expose risk of leakage. All PVCs are encrypted and cloud-native databases like Aurora are provisioned with the best practice security policies like encryption at rest . Certificate management happpens on the cloud provider like AWS Certificate Manager ( ACM ) and required SSL and TLS configurations adopted that are recommended by the cloud provider. Access Control Just in time, temporary credentials are issued in the Facets control plane for anyone who wants to access the kubernetes cluster for maintenance activities. This token expires in 24 hours. The user privileges are controlled by the admins of Facets control plane. Any management port that is required to be exposed by the application/service uses a tools ingress that is password protected. Facets comes with pre-integration with Zero trust Application Access systems such as Cloudflare Access .","title":"Compliance & Security"},{"location":"tools/compliance/#compliance-and-security-controls","text":"Facets.cloud encourages secure practices and out of the box security tools. This enables any cluster launched through facets.cloud to be easier for compliance with minimal involvement of technology team in the process. Facets.cloud doesn't provide any proprietary tools for security rather aim to integrate with existing opensource and paid tool options. The scope of the compliance here is the cloud security parts only that is launched and managed by facets.cloud Depending on the industry you operate in, the following standards may be applicable to you * ISO * PCI DSS * SOC-2 Broadly, the cloud security scope falls into the following areas","title":"Compliance and Security Controls"},{"location":"tools/compliance/#infrastructure-security-practices","text":"","title":"Infrastructure Security Practices"},{"location":"tools/compliance/#deployment-of-facetscloud","text":"Facets.cloud is deployed on the customer's premises as a licensed solution. It is recommended that this is deployed in a standalone AWS account following AWS Organizations best practices. This excludes any thirdparty infrastructure to come additionally in the security and complaince scope.","title":"Deployment of Facets.cloud"},{"location":"tools/compliance/#high-level-deployment-model","text":"Any cluster deployed through Facets.cloud follows best practices recommended by the cloud vendor. For e.g., in the case of AWS, the underlying infrastructure contains an EKS cluster hosted inside private subnet of a VPC. By default, there is no direct connectivity to the EKS cluster from outside unless an application explicitly specifies it. This specification if provided, goes through the Stack definition of the application and hence checked in a git repository. Apart from the advantages of this practice being declarative in nature, specific to security and compliance, it provides the following advantages - * Named (Who created/updated it) * Version controlled * Process controlled (Secondary sign-off using PR Reviews) * easily auditable","title":"High level deployment model"},{"location":"tools/compliance/#antivirus-hids","text":"ClamAV are installed in every node launched by Facets. Facets is responsible for updating and ensuring the ClamAV agents are running all the time. ClamAV antivirus scan results are pushed to a permanent storage from which the results can be downloaded. In future, these results will be available in SIEM dashboard as well.","title":"Antivirus (HIDS)"},{"location":"tools/compliance/#security-information-and-event-management-siem","text":"Facets.cloud comes with pre-integration with Falco . Falco provides the cloud-native runtime security and is the de-facto Kubernetes threat detection engine. Falco ships with a default set of rules that check the kernel for unusual behaviors. Read the falco features here . Any cluster launched by Facets contains prometheus and grafana by default. Falco output metrics are parsed and sent to prometheus for the infromation security team to monitor and custommize the standard dashboards provided by Facets. Additionally, if a paid tool like Newrelic is enabled, these metrics automatically gets pushed to Newrelic for a cluster-wide view.","title":"Security Information and Event Management (SIEM)"},{"location":"tools/compliance/#firewall-nids","text":"A cloud launched by Facets will have ModSecurity installed at the ingress points. Any application developer who wants to expose a web server port to the outside world must define an ingress rule in the application stack definition. Facets injects ModSecurity with OWASP ModSecurity Core Rule Set . Similar to Falco, the output is sent to prometheus/grafana and can be optionally relayed to third party monitoring tools like Newrelic as well. An information Security personnel can customize the rules for alerting.","title":"Firewall (NIDS)"},{"location":"tools/compliance/#security-practices","text":"","title":"Security Practices"},{"location":"tools/compliance/#network-security-and-iam","text":"All resources are provisioned by Facets during the cluster launch and update based on CredentialRequests. The credentials requested by any application is only available to that application. QA, Stage and production environments are created separately in Facets with share nothing principles. All physical resources are created in private subnet of the VPC and only uses a NAT gateway for outbound traffic By default, no network traffic is allowed to the network with deny-all policies. Any application that needs an ingress route is injected by a ModSecurity WAF. This is as per the DMZ (De-Militarized Zone) best practices.","title":"Network, Security and IAM"},{"location":"tools/compliance/#secrets-encryption-and-key-management","text":"Database, Cloud resource secrets are requested by the applications in the stack definitions and fulfilled by facets at the cluster launch. This eliminates any need of a manual password or access creation that can potentially expose risk of leakage. All PVCs are encrypted and cloud-native databases like Aurora are provisioned with the best practice security policies like encryption at rest . Certificate management happpens on the cloud provider like AWS Certificate Manager ( ACM ) and required SSL and TLS configurations adopted that are recommended by the cloud provider.","title":"Secrets, Encryption and Key management"},{"location":"tools/compliance/#access-control","text":"Just in time, temporary credentials are issued in the Facets control plane for anyone who wants to access the kubernetes cluster for maintenance activities. This token expires in 24 hours. The user privileges are controlled by the admins of Facets control plane. Any management port that is required to be exposed by the application/service uses a tools ingress that is password protected. Facets comes with pre-integration with Zero trust Application Access systems such as Cloudflare Access .","title":"Access Control"},{"location":"tools/observability/","text":"Observability The following are usually the three levers to build in-depth observability to your application deployments in production environment * Metrics * Logs * Tracing Metrics The deployments created through Facets ships with a built-in Grafana and Prometheus set up with pre-integrations to standard components and relevant dashboards. The Grafana dashboard can be accessed through the control plane or with cluster specific URLs by the develops, devops and support staff. The metrics collected by Prometheus are usually of the following types * Infrastructure Metrics (Pre-built metric exporters) * Application Metrics ( Open telemetry ) Infrastructure Metrics Any components instantiated through Facets comes with the relevant pre-built metrics dashboards. The following graphs shows a pre-built redis dashboard. Application Metrics Facets.cloud adopts Open Telemetry standards for pushing metrics. Applications expose metrics as end-points and declare it as a monitoring object inside the FSDL application specifications. Facets.cloud instruments the scraping of these metrics out of the application metrics end-points and submits to Prometheus. User Defined Dashboards Dashboards can also be defined in Facet stack definition language by committing the exported json from grafana into the stack definition place the json file in /dashboards/instances directory in your stack Metrics Integrations with third party tools You can use your favourite third-party tools like Newrelic to visualize the metrics apart from the Grafana dashboard. The Newrelic pre-integration relays metrics from prometheus to Newrelic without any other code change to the application. Add NEWRELIC_LICENSE_KEY to the Common Environment Variables to enable the pre-integration. The following shows the earlier redis dashboard on newrelic. Logs Facets expects all application containers to log to system.out . For most languages, this can be achieved by using a console appender to the code. Facets uses fluentd to relay logs and presents various options of log collection. NFS with object storage as backup This option usually translates to an EFS with S3 if the deployment is on AWS cloud. This option by default acts as the source of truth of all the log storage at a single place. The logs are organized as folders in application/containers and get pushed to S3 at configured time interval.The logs can be accessed through a Wetty terminal after a required authorization by the user. Older logs can be downloaded from s3 on need-basis on the same console. Additional logging substacks ELK - Additional to EFS/NFS as logging, an ELK substack can be chosen to index and search the logs. Depending on the log volumes produced by the applications per-day, this may be an effective solution More log collection options are in development .. Traces Facets doesn't provide any tracing integrations yet. Tracing is usually instrumented inside the application code. Alerts All active and inactive alerts can be obtained through Alerts dropdown in the control plane. The set of alerts can be categorized in to two parts 1. Standard Alerts - Facets ships standard alerts with each component that is defined in the stack. 2. User defined Alerts - Additionally, alerts can be defined in PromQL and committed in the stack git repo, which will be automatically available in all deployments These Alerts can be defined in Facet stack definition language by committing the alertmanager yaml into the stack definition place the yaml file in /alerts/instances directory in your stack Sample Yaml File: - name: mongo.rules rules: - alert: MongoRelicaStatusSecondaryCrit expr: mongodb_mongod_replset_member_state{state=\"SECONDARY\"} != 2 for: 2m labels: severity: critical team: infra resourceType: mongo resourceName: \"{{ $labels.pod_name }}\" annotations: message: MongoDB secondary replica status down The alerts can be pushed to ChatOPs tools like Slack or flock. Any team that has added the corresponding module as an observer, receives the alert for that module by the channel updates.","title":"Observability"},{"location":"tools/observability/#observability","text":"The following are usually the three levers to build in-depth observability to your application deployments in production environment * Metrics * Logs * Tracing","title":"Observability"},{"location":"tools/observability/#metrics","text":"The deployments created through Facets ships with a built-in Grafana and Prometheus set up with pre-integrations to standard components and relevant dashboards. The Grafana dashboard can be accessed through the control plane or with cluster specific URLs by the develops, devops and support staff. The metrics collected by Prometheus are usually of the following types * Infrastructure Metrics (Pre-built metric exporters) * Application Metrics ( Open telemetry )","title":"Metrics"},{"location":"tools/observability/#infrastructure-metrics","text":"Any components instantiated through Facets comes with the relevant pre-built metrics dashboards. The following graphs shows a pre-built redis dashboard.","title":"Infrastructure Metrics"},{"location":"tools/observability/#application-metrics","text":"Facets.cloud adopts Open Telemetry standards for pushing metrics. Applications expose metrics as end-points and declare it as a monitoring object inside the FSDL application specifications. Facets.cloud instruments the scraping of these metrics out of the application metrics end-points and submits to Prometheus.","title":"Application Metrics"},{"location":"tools/observability/#user-defined-dashboards","text":"Dashboards can also be defined in Facet stack definition language by committing the exported json from grafana into the stack definition place the json file in /dashboards/instances directory in your stack","title":"User Defined Dashboards"},{"location":"tools/observability/#metrics-integrations-with-third-party-tools","text":"You can use your favourite third-party tools like Newrelic to visualize the metrics apart from the Grafana dashboard. The Newrelic pre-integration relays metrics from prometheus to Newrelic without any other code change to the application. Add NEWRELIC_LICENSE_KEY to the Common Environment Variables to enable the pre-integration. The following shows the earlier redis dashboard on newrelic.","title":"Metrics Integrations with third party tools"},{"location":"tools/observability/#logs","text":"Facets expects all application containers to log to system.out . For most languages, this can be achieved by using a console appender to the code. Facets uses fluentd to relay logs and presents various options of log collection.","title":"Logs"},{"location":"tools/observability/#nfs-with-object-storage-as-backup","text":"This option usually translates to an EFS with S3 if the deployment is on AWS cloud. This option by default acts as the source of truth of all the log storage at a single place. The logs are organized as folders in application/containers and get pushed to S3 at configured time interval.The logs can be accessed through a Wetty terminal after a required authorization by the user. Older logs can be downloaded from s3 on need-basis on the same console.","title":"NFS with object storage as backup"},{"location":"tools/observability/#additional-logging-substacks","text":"ELK - Additional to EFS/NFS as logging, an ELK substack can be chosen to index and search the logs. Depending on the log volumes produced by the applications per-day, this may be an effective solution More log collection options are in development ..","title":"Additional logging substacks"},{"location":"tools/observability/#traces","text":"Facets doesn't provide any tracing integrations yet. Tracing is usually instrumented inside the application code.","title":"Traces"},{"location":"tools/observability/#alerts","text":"All active and inactive alerts can be obtained through Alerts dropdown in the control plane. The set of alerts can be categorized in to two parts 1. Standard Alerts - Facets ships standard alerts with each component that is defined in the stack. 2. User defined Alerts - Additionally, alerts can be defined in PromQL and committed in the stack git repo, which will be automatically available in all deployments These Alerts can be defined in Facet stack definition language by committing the alertmanager yaml into the stack definition place the yaml file in /alerts/instances directory in your stack Sample Yaml File: - name: mongo.rules rules: - alert: MongoRelicaStatusSecondaryCrit expr: mongodb_mongod_replset_member_state{state=\"SECONDARY\"} != 2 for: 2m labels: severity: critical team: infra resourceType: mongo resourceName: \"{{ $labels.pod_name }}\" annotations: message: MongoDB secondary replica status down The alerts can be pushed to ChatOPs tools like Slack or flock. Any team that has added the corresponding module as an observer, receives the alert for that module by the channel updates.","title":"Alerts"}]}